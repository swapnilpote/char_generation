{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-09-10 21:41:34--  https://www.gutenberg.org/files/11/11-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 2610:28:3090:3000:0:bad:cafe:47, 152.19.134.47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|2610:28:3090:3000:0:bad:cafe:47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 173595 (170K) [text/plain]\n",
      "Saving to: '11-0.txt'\n",
      "\n",
      "11-0.txt            100%[===================>] 169.53K   128KB/s    in 1.3s    \n",
      "\n",
      "2018-09-10 21:41:37 (128 KB/s) - '11-0.txt' saved [173595/173595]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.gutenberg.org/files/11/11-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv 11-0.txt data/wonderland.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/wonderland.txt\"\n",
    "raw_text = open(filename, encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffproject gutenberg’s alice’s adventures in wonderland, by lewis carroll\\n\\nthis ebook is for the use o'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  163817\n",
      "Total Vocab:  61\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patterns = len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  163717\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "163717/163717 [==============================] - 27s 165us/step - loss: 3.0623\n",
      "Epoch 2/20\n",
      "163717/163717 [==============================] - 27s 166us/step - loss: 3.0479\n",
      "Epoch 3/20\n",
      "163717/163717 [==============================] - 27s 166us/step - loss: 3.0006\n",
      "Epoch 4/20\n",
      "163717/163717 [==============================] - 27s 167us/step - loss: 2.9465\n",
      "Epoch 5/20\n",
      "163717/163717 [==============================] - 27s 167us/step - loss: 2.9214\n",
      "Epoch 6/20\n",
      "163717/163717 [==============================] - 27s 167us/step - loss: 2.9029\n",
      "Epoch 7/20\n",
      "163717/163717 [==============================] - 27s 167us/step - loss: 2.8847\n",
      "Epoch 8/20\n",
      "163717/163717 [==============================] - 27s 167us/step - loss: 2.8674\n",
      "Epoch 9/20\n",
      "163717/163717 [==============================] - 27s 167us/step - loss: 2.8520\n",
      "Epoch 10/20\n",
      "163717/163717 [==============================] - 27s 168us/step - loss: 2.8371\n",
      "Epoch 11/20\n",
      "163717/163717 [==============================] - 27s 168us/step - loss: 2.8215\n",
      "Epoch 12/20\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.8025\n",
      "Epoch 13/20\n",
      "163717/163717 [==============================] - 27s 168us/step - loss: 2.7848\n",
      "Epoch 14/20\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.7657\n",
      "Epoch 15/20\n",
      "163717/163717 [==============================] - 27s 168us/step - loss: 2.7470\n",
      "Epoch 16/20\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.7299\n",
      "Epoch 17/20\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.7135\n",
      "Epoch 18/20\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.6992\n",
      "Epoch 19/20\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.6836\n",
      "Epoch 20/20\n",
      "163717/163717 [==============================] - 27s 168us/step - loss: 2.6706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5a800bdcc0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs = 20, batch_size = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" door of which was a bright brass\n",
      "plate with the name ‘w. rabbit’ engraved upon it. she went in witho \"\n",
      " toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe toe\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.3553\n",
      "Epoch 2/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.3424\n",
      "Epoch 3/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.3298\n",
      "Epoch 4/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.3154\n",
      "Epoch 5/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.3060\n",
      "Epoch 6/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.2951\n",
      "Epoch 7/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.2818\n",
      "Epoch 8/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.2706\n",
      "Epoch 9/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.2602\n",
      "Epoch 10/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.2481\n",
      "Epoch 11/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.2377\n",
      "Epoch 12/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.2295\n",
      "Epoch 13/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.2163\n",
      "Epoch 14/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.2102\n",
      "Epoch 15/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1992\n",
      "Epoch 16/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1850\n",
      "Epoch 17/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1761\n",
      "Epoch 18/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1675\n",
      "Epoch 19/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1582\n",
      "Epoch 20/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1494\n",
      "Epoch 21/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1411\n",
      "Epoch 22/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1333\n",
      "Epoch 23/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1259\n",
      "Epoch 24/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1144\n",
      "Epoch 25/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1100\n",
      "Epoch 26/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0993\n",
      "Epoch 27/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0953\n",
      "Epoch 28/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0840\n",
      "Epoch 29/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0758\n",
      "Epoch 30/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0681\n",
      "Epoch 31/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0638\n",
      "Epoch 32/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0577\n",
      "Epoch 33/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0508\n",
      "Epoch 34/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0412\n",
      "Epoch 35/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0365\n",
      "Epoch 36/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0264\n",
      "Epoch 37/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0245\n",
      "Epoch 38/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0183\n",
      "Epoch 39/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0091\n",
      "Epoch 40/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0026\n",
      "Epoch 41/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9914\n",
      "Epoch 42/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9887\n",
      "Epoch 43/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9813\n",
      "Epoch 44/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9768\n",
      "Epoch 45/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9791\n",
      "Epoch 46/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9673\n",
      "Epoch 47/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9652\n",
      "Epoch 48/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9595\n",
      "Epoch 49/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9562\n",
      "Epoch 50/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9458\n",
      "Epoch 51/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9392\n",
      "Epoch 52/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9401\n",
      "Epoch 53/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9328\n",
      "Epoch 54/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9257\n",
      "Epoch 55/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9211\n",
      "Epoch 56/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9226\n",
      "Epoch 57/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9159\n",
      "Epoch 58/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9100\n",
      "Epoch 59/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9002\n",
      "Epoch 60/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9021\n",
      "Epoch 61/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8951\n",
      "Epoch 62/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8956\n",
      "Epoch 63/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8967\n",
      "Epoch 64/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8821\n",
      "Epoch 65/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8841\n",
      "Epoch 66/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8728\n",
      "Epoch 67/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8740\n",
      "Epoch 68/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8713\n",
      "Epoch 69/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8733\n",
      "Epoch 70/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8600\n",
      "Epoch 71/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8548\n",
      "Epoch 72/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8507\n",
      "Epoch 73/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8547\n",
      "Epoch 74/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8443\n",
      "Epoch 75/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8400\n",
      "Epoch 76/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8447\n",
      "Epoch 77/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8341\n",
      "Epoch 78/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8298\n",
      "Epoch 79/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8236\n",
      "Epoch 80/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8317\n",
      "Epoch 81/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8227\n",
      "Epoch 82/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8153\n",
      "Epoch 83/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8175\n",
      "Epoch 84/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8138\n",
      "Epoch 85/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8006\n",
      "Epoch 86/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8054\n",
      "Epoch 87/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8036\n",
      "Epoch 88/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7982\n",
      "Epoch 89/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7986\n",
      "Epoch 90/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7950\n",
      "Epoch 91/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7908\n",
      "Epoch 92/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7869\n",
      "Epoch 93/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7771\n",
      "Epoch 94/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7816\n",
      "Epoch 95/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7801\n",
      "Epoch 96/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7811\n",
      "Epoch 97/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7751\n",
      "Epoch 98/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7737\n",
      "Epoch 99/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7653\n",
      "Epoch 100/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7591\n",
      "Epoch 101/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7581\n",
      "Epoch 102/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7570\n",
      "Epoch 103/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7559\n",
      "Epoch 104/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7472\n",
      "Epoch 105/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7431\n",
      "Epoch 106/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7461\n",
      "Epoch 107/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7403\n",
      "Epoch 108/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7387\n",
      "Epoch 109/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7437\n",
      "Epoch 110/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7325\n",
      "Epoch 111/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7341\n",
      "Epoch 112/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7331\n",
      "Epoch 113/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7291\n",
      "Epoch 114/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7228\n",
      "Epoch 115/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7255\n",
      "Epoch 116/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7215\n",
      "Epoch 117/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7188\n",
      "Epoch 118/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7162\n",
      "Epoch 119/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7100\n",
      "Epoch 120/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8158\n",
      "Epoch 121/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0632\n",
      "Epoch 122/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9334\n",
      "Epoch 123/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9204\n",
      "Epoch 124/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9361\n",
      "Epoch 125/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8562\n",
      "Epoch 126/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7997\n",
      "Epoch 127/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7919\n",
      "Epoch 128/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7750\n",
      "Epoch 129/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7570\n",
      "Epoch 130/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7399\n",
      "Epoch 131/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0197\n",
      "Epoch 132/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1061\n",
      "Epoch 133/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9220\n",
      "Epoch 134/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8407\n",
      "Epoch 135/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7941\n",
      "Epoch 136/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7688\n",
      "Epoch 137/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7476\n",
      "Epoch 138/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7310\n",
      "Epoch 139/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7235\n",
      "Epoch 140/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7192\n",
      "Epoch 141/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7129\n",
      "Epoch 142/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7089\n",
      "Epoch 143/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7109\n",
      "Epoch 144/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7103\n",
      "Epoch 145/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6933\n",
      "Epoch 146/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7000\n",
      "Epoch 147/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6900\n",
      "Epoch 148/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6891\n",
      "Epoch 149/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6846\n",
      "Epoch 150/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6849\n",
      "Epoch 151/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6799\n",
      "Epoch 152/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6738\n",
      "Epoch 153/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6735\n",
      "Epoch 154/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6776\n",
      "Epoch 155/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6738\n",
      "Epoch 156/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6631\n",
      "Epoch 157/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6678\n",
      "Epoch 158/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6642\n",
      "Epoch 159/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6582\n",
      "Epoch 160/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6929\n",
      "Epoch 161/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6846\n",
      "Epoch 162/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8072\n",
      "Epoch 163/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8162\n",
      "Epoch 164/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7037\n",
      "Epoch 165/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6813\n",
      "Epoch 166/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6666\n",
      "Epoch 167/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6583\n",
      "Epoch 168/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6553\n",
      "Epoch 169/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6508\n",
      "Epoch 170/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6470\n",
      "Epoch 171/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6433\n",
      "Epoch 172/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6339\n",
      "Epoch 173/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6400\n",
      "Epoch 174/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6336\n",
      "Epoch 175/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6278\n",
      "Epoch 176/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6320\n",
      "Epoch 177/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6313\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6301\n",
      "Epoch 179/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6185\n",
      "Epoch 180/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6165\n",
      "Epoch 181/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6161\n",
      "Epoch 182/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6200\n",
      "Epoch 183/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6233\n",
      "Epoch 184/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6293\n",
      "Epoch 185/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6209\n",
      "Epoch 186/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6174\n",
      "Epoch 187/200\n",
      "163717/163717 [==============================] - 28s 171us/step - loss: 1.6110\n",
      "Epoch 188/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6051\n",
      "Epoch 189/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5963\n",
      "Epoch 190/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5963\n",
      "Epoch 191/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5980\n",
      "Epoch 192/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5984\n",
      "Epoch 193/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6055\n",
      "Epoch 194/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6037\n",
      "Epoch 195/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5939\n",
      "Epoch 196/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5936\n",
      "Epoch 197/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5879\n",
      "Epoch 198/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5907\n",
      "Epoch 199/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5885\n",
      "Epoch 200/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5a800b5b00>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs = 200, batch_size = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" -frame, or something of the sort.\n",
      "\n",
      "next came an angry voice--the rabbit’s--‘pat! pat! where are you? \"\n",
      "’\n",
      "\n",
      "‘he ding wuitei sue of the cane  sh ceow! io wou dol lede toer ’iu fanet to te the haoter tn the tei. aud shrt wi thal sht wast teen s shen hame a arin and a fatee sa soahe wottg to moke ’hu go toutend io the sane thi  and wein is totl an an aace aod, tiad a lorgle hearee, and sheu hne titt aliie whsh sn hnrsel. ‘ih wou doo the moot of the gint an th she whit h tait to the koreronni to the hamde.\n",
      "\n",
      "‘hel a din hor here ay all ali ailiti an atl aelit th tee teessd ’ aad a donwlrnsel ioputent on oone then  ane to do wout the whet  in wound fo tae iott of the gant, aad a lirtle thich a lailee at an  ald e gon  fo a loade to thi the that an the tirtoe of the saad thtt bf tne cal an the calle. ‘ou meas t she said to hheself, at sae had no ven ergluiin tein ites to then at the sagted het  and theughe th the tart tfeisi gor the rioe the was toteli then woued an toel i sheee thttle tane toe dan er att more. \n",
      "‘he iorr wuing i saon ’ sai hatter wailiue.\n",
      "\n",
      "‘oo most theegy wase oo c gottne paase’ \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5808\n",
      "Epoch 2/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5841\n",
      "Epoch 3/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5776\n",
      "Epoch 4/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5866\n",
      "Epoch 5/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5859\n",
      "Epoch 6/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5757\n",
      "Epoch 7/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5792\n",
      "Epoch 8/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5695\n",
      "Epoch 9/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5776\n",
      "Epoch 10/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5687\n",
      "Epoch 11/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5604\n",
      "Epoch 12/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5698\n",
      "Epoch 13/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5680\n",
      "Epoch 14/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5562\n",
      "Epoch 15/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5710\n",
      "Epoch 16/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5702\n",
      "Epoch 17/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5584\n",
      "Epoch 18/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5544\n",
      "Epoch 19/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5528\n",
      "Epoch 20/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5533\n",
      "Epoch 21/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5555\n",
      "Epoch 22/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5465\n",
      "Epoch 23/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5477\n",
      "Epoch 24/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5446\n",
      "Epoch 25/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5501\n",
      "Epoch 26/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5756\n",
      "Epoch 27/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5617\n",
      "Epoch 28/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5502\n",
      "Epoch 29/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5377\n",
      "Epoch 30/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5356\n",
      "Epoch 31/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5310\n",
      "Epoch 35/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5313\n",
      "Epoch 36/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5307\n",
      "Epoch 37/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5200\n",
      "Epoch 38/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5304\n",
      "Epoch 39/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5285\n",
      "Epoch 40/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5253\n",
      "Epoch 41/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5246\n",
      "Epoch 42/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5258\n",
      "Epoch 43/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5242\n",
      "Epoch 44/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5141\n",
      "Epoch 45/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5225\n",
      "Epoch 46/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5171\n",
      "Epoch 47/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5119\n",
      "Epoch 48/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5129\n",
      "Epoch 49/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5179\n",
      "Epoch 50/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5170\n",
      "Epoch 51/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5113\n",
      "Epoch 52/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5124\n",
      "Epoch 53/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5081\n",
      "Epoch 54/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5111\n",
      "Epoch 55/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4991\n",
      "Epoch 56/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5132\n",
      "Epoch 57/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5049\n",
      "Epoch 58/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4997\n",
      "Epoch 59/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4993\n",
      "Epoch 60/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4969\n",
      "Epoch 61/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4982\n",
      "Epoch 62/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4900\n",
      "Epoch 63/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5055\n",
      "Epoch 64/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4921\n",
      "Epoch 65/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4857\n",
      "Epoch 66/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4975\n",
      "Epoch 67/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5055\n",
      "Epoch 68/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4819\n",
      "Epoch 69/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4892\n",
      "Epoch 70/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4857\n",
      "Epoch 71/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4909\n",
      "Epoch 72/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4838\n",
      "Epoch 73/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4840\n",
      "Epoch 74/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4875\n",
      "Epoch 75/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.4807\n",
      "Epoch 76/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5119\n",
      "Epoch 77/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6137\n",
      "Epoch 78/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5742\n",
      "Epoch 79/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9870\n",
      "Epoch 80/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1945\n",
      "Epoch 81/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1575\n",
      "Epoch 82/200\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.6600\n",
      "Epoch 83/200\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.9446\n",
      "Epoch 84/200\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.8510\n",
      "Epoch 85/200\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.8144\n",
      "Epoch 86/200\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.7875\n",
      "Epoch 87/200\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.7655\n",
      "Epoch 88/200\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.7459\n",
      "Epoch 89/200\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.7261\n",
      "Epoch 90/200\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.7094\n",
      "Epoch 91/200\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.6945\n",
      "Epoch 92/200\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.6790\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.6630\n",
      "Epoch 94/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.6483\n",
      "Epoch 95/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.6336\n",
      "Epoch 96/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.6163\n",
      "Epoch 97/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.6006\n",
      "Epoch 98/200\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.5838\n",
      "Epoch 99/200\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.5686\n",
      "Epoch 100/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.5521\n",
      "Epoch 101/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.5361\n",
      "Epoch 102/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.5198\n",
      "Epoch 103/200\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.5005\n",
      "Epoch 104/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.4846\n",
      "Epoch 105/200\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.4686\n",
      "Epoch 106/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.4478\n",
      "Epoch 107/200\n",
      "163717/163717 [==============================] - 28s 168us/step - loss: 2.4292\n",
      "Epoch 108/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.4110\n",
      "Epoch 109/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.3896\n",
      "Epoch 110/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.3717\n",
      "Epoch 111/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.3518\n",
      "Epoch 112/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.3310\n",
      "Epoch 113/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.3111\n",
      "Epoch 114/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.2890\n",
      "Epoch 115/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.2669\n",
      "Epoch 116/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.2428\n",
      "Epoch 117/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.2193\n",
      "Epoch 118/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1943\n",
      "Epoch 119/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1703\n",
      "Epoch 120/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1476\n",
      "Epoch 121/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1276\n",
      "Epoch 122/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.1061\n",
      "Epoch 123/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0824\n",
      "Epoch 124/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0629\n",
      "Epoch 125/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0457\n",
      "Epoch 126/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0234\n",
      "Epoch 127/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 2.0087\n",
      "Epoch 128/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9947\n",
      "Epoch 129/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9793\n",
      "Epoch 130/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9664\n",
      "Epoch 131/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9523\n",
      "Epoch 132/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9374\n",
      "Epoch 133/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9284\n",
      "Epoch 134/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9158\n",
      "Epoch 135/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.9045\n",
      "Epoch 136/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8882\n",
      "Epoch 137/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8779\n",
      "Epoch 138/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8690\n",
      "Epoch 139/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8590\n",
      "Epoch 140/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8455\n",
      "Epoch 141/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8431\n",
      "Epoch 142/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8300\n",
      "Epoch 143/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8216\n",
      "Epoch 144/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8135\n",
      "Epoch 145/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.8011\n",
      "Epoch 146/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7911\n",
      "Epoch 147/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7809\n",
      "Epoch 148/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7719\n",
      "Epoch 149/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7731\n",
      "Epoch 150/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7630\n",
      "Epoch 151/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7558\n",
      "Epoch 152/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7488\n",
      "Epoch 153/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7355\n",
      "Epoch 154/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7334\n",
      "Epoch 155/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7234\n",
      "Epoch 156/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7133\n",
      "Epoch 157/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7070\n",
      "Epoch 158/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.7043\n",
      "Epoch 159/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6985\n",
      "Epoch 160/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6944\n",
      "Epoch 161/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6821\n",
      "Epoch 162/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6841\n",
      "Epoch 163/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6758\n",
      "Epoch 164/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6650\n",
      "Epoch 165/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6559\n",
      "Epoch 166/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6578\n",
      "Epoch 167/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6469\n",
      "Epoch 168/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6474\n",
      "Epoch 169/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6393\n",
      "Epoch 170/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6329\n",
      "Epoch 171/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6302\n",
      "Epoch 172/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6266\n",
      "Epoch 173/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6232\n",
      "Epoch 174/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6160\n",
      "Epoch 175/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6070\n",
      "Epoch 176/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.6049\n",
      "Epoch 177/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5949\n",
      "Epoch 178/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5926\n",
      "Epoch 179/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5941\n",
      "Epoch 180/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5843\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5737\n",
      "Epoch 182/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5695\n",
      "Epoch 183/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5763\n",
      "Epoch 184/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5781\n",
      "Epoch 185/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5624\n",
      "Epoch 186/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5617\n",
      "Epoch 187/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5560\n",
      "Epoch 188/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5441\n",
      "Epoch 189/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5494\n",
      "Epoch 190/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5389\n",
      "Epoch 191/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5359\n",
      "Epoch 192/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5316\n",
      "Epoch 193/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5320\n",
      "Epoch 194/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5300\n",
      "Epoch 195/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5248\n",
      "Epoch 196/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5236\n",
      "Epoch 197/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5192\n",
      "Epoch 198/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5147\n",
      "Epoch 199/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5162\n",
      "Epoch 200/200\n",
      "163717/163717 [==============================] - 28s 169us/step - loss: 1.5031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5a800b5dd8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs = 200, batch_size = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" holding her hand on the top of her head to feel which way it was\n",
      "growing, and she was quite surprise \"\n",
      "d to tei dttliused th the kihte th hea feae with soeye \n",
      "ant saed in tistled tn the ooher.\n",
      "\n",
      "‘h sast t said the moek turtle: ‘woul the wer \n",
      "so doan an ay s\n",
      "shi shid uo the ali totie tnterfeng to aerin in one.\n",
      "\n",
      "‘if porene thing in the docw tae the gurarss tniee-’ she said to herself, sto wou doont anf dork thet here an serering and then it tootle oh be inle wo then, thte an the was a little oo st the wastin an oo eo the dareepiller.\n",
      "\n",
      "‘hede if ane wout an “our oay,’ taid alice in a sera of thict hrdee.\n",
      "and shen see werter an toe want te thet sere the dande hat and to deve peane whst saresg anonss, and test iu had io the buihesss ceore thined. and tone i cei’t han  nouc co whet tound toung to bete in the sonte oi the hand  nhe more toitting oo hanted. \n",
      "‘when if yhu gren toe gan,’ taed alice, ‘ard tou dou’t sale tou dn wou th thin, i whntt is woul oo biong an mn eo ths oose ’uur lake to the seat the sent then, \n",
      "‘hed a din tht trine on a taat to the danens init i whe korte sh the saite, ‘it i\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
